ğŸš€ AI-Powered Product Search Engine (Vespa + Node.js)

A lightweight, assignment-friendly keyword + vector search system built with Vespa.ai, Node.js, and Docker, supporting multi-tenant CRUD, BM25 search, vector search, and rate limiting.

This project provides a simple but complete demo of a production-style search backend.

âœ… Project Status

âœ” Vespa running in Docker
âœ” Application package deployed
âœ” Document CRUD API (Node.js)
âœ” BM25 keyword search
âœ” Vector similarity search (static embeddings placeholder)
âœ” Per-tenant rate limiting
âœ” LRU caching layer
âœ” Postman tested
âœ” Complete documentation included

âœ¨ Features

ğŸ” Full-text BM25 search (title, body, tags)

ğŸ“„ Document CRUD (create / fetch / delete)

ğŸ§  Vector search using Vespa nearest-neighbor

ğŸ”’ Per-tenant rate limiting (simple in-memory)

âš¡ LRU caching for search queries

ğŸ³ Docker Compose local setup

ğŸŒ Multi-tenant indexing (via tenant query param)

ğŸ“¬ Postman collection provided

ğŸ›  Tech Stack
- Vespa.ai (Search + Vector Index)
- Node.js (Express.js REST API)
- Docker + Docker Compose
- LRU Cache (in-memory)
- HuggingFace embeddings (optional future enhancement)
- Postman for testing

ğŸ— Architecture Overview

Node.js API receives documents

(Optional) embeddings can be generated â€” static vector used currently

API feeds documents into Vespa (/document/v1/...)

Vespa indexes + stores

Search queries â†’ API â†’ Vespa /search

ğŸ“ Folder Structure

```
search-engine/
â”œâ”€â”€ api/                     # Node.js API
â”‚   â”œâ”€â”€ index.js
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ documents.js
â”‚   â”‚   â”œâ”€â”€ search.js
â”‚   â”‚   â””â”€â”€ health.js
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ vespaClient.js
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ embedding.js
â”‚   â”‚   â””â”€â”€ errors.js
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â””â”€â”€ rateLimit.js
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ config.js
â”‚
â”œâ”€â”€ vespa-app/               # Vespa application
â”‚   â”œâ”€â”€ deployment.xml
â”‚   â”œâ”€â”€ services.xml
â”‚   â””â”€â”€ schemas/
â”‚       â””â”€â”€ doc.sd
â”‚
â”œâ”€â”€ docs/                    # Documentation
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ vespa-setup-and-postman-guide.md
â”‚   â””â”€â”€ Search.postman_collection.json
â”‚
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

ğŸ“¡ API Endpoints Overview

**Documents**
| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/documents?tenant={id}` | Create / index a document (tenant required) |
| GET | `/documents/{id}?tenant={id}` | Retrieve a document by ID (tenant required for rate limiting) |
| DELETE | `/documents/{id}?tenant={id}` | Delete document by ID (tenant required for rate limiting) |

**Search**
| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/search?q={query}&tenant={id}` | BM25 keyword search |
| GET | `/search?q={query}&tenant={id}&vector=true` | Vector similarity search (uses static [0.5...] query vector) |

**Health Check**
| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/health` | Health check + Vespa dependency status |
âš™ï¸ Quick Start
1. Clone Repo
git clone <your-repo-url>
cd search-engine

2. Start Docker Services
docker-compose up --build

3. Deploy Vespa Application
docker exec -it vespa bash
/opt/vespa/bin/vespa-deploy prepare /app
/opt/vespa/bin/vespa-deploy activate <SESSION_ID>

4. Check Vespa Health
http://localhost:8080/state/v1/health

ğŸ§ª Testing with Postman

Import the collection located at:

docs/Search.postman_collection.json


Includes:

âœ” Insert document
âœ” BM25 search
âœ” Vector search
âœ” Delete document

ğŸ”® Future Enhancements / Possibilities

These make the project production-ready:

Real HuggingFace embeddings (MiniLM, ColBERT, GTE, MPNetâ€¦)

Hybrid ranking: BM25 + ANN fusion

Redis-based cache + rate limiting

Search UI dashboard

Query rewriting + spelling correction

Multi-tenant isolation via namespaces

Facets, filters, and aggregations

âš ï¸ Simplifications for Assignment

To keep the demo simple and quick to review:

- Vector search uses static placeholder query vector [0.5, ..., 0.5] (128 dims)
- Document vectors are generated from title+body using hash-based algorithm
- Rate limiting uses in-memory storage (not Redis) - 100 req/min per tenant
- LRU cache is in-memory only (30s TTL, max 200 entries)
- No authentication needed
- Basic logging only
